{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 7318210 characters, 146 unique.\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print(f\"data has {data_size:d} characters, {vocab_size:d} unique.\")\n",
    "\n",
    "        self.stoi = { ch: i for i, ch in enumerate(chars) }\n",
    "        self.itos = { i: ch for i, ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx+self.block_size+1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "       \n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "block_size = 128  \n",
    "\n",
    "text = open('input15.txt', 'r').read()\n",
    "\n",
    "train_dataset = CharDataset(text, block_size = 128) \n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=2,\n",
    "    batch_size=912,\n",
    "    learning_rate=6e-4,\n",
    "    lr_decay=True,\n",
    "    warmup_tokens=512*20,\n",
    "    final_tokens=2*len(train_dataset)*block_size,\n",
    "    num_workers=8,\n",
    "    ckpt_path = './kan-gpt-instruct.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.kan import *\n",
    "\n",
    "config = GPTConfig(\n",
    "    train_dataset.vocab_size,\n",
    "    train_dataset.block_size,\n",
    "    n_layer=4,\n",
    "    n_head=8,\n",
    "    n_embd=512,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(config)\n",
    "model.load_state_dict(torch.load('./kan-gpt-instruct.pth'))\n",
    "model.to(torch.device('cuda'))\n",
    "trainer = Trainer(model, train_dataset, None, tconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human> What technology does Apple use?<endOfText>\n",
      "<bot> hi i just installed ubuntu in the menu<endOfText>\n",
      "<human> can you post the drive?<endOfText>\n",
      "<bot> p\n"
     ]
    }
   ],
   "source": [
    "from mingpt.utils import sample\n",
    "\n",
    "context = \"<human> What technology does Apple use?<endOfText>\\n<bot> \"\n",
    "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(trainer.device)\n",
    "y = sample(model, x, 100, temperature=0.8, sample=True, top_k=40)[0]\n",
    "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "print(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
